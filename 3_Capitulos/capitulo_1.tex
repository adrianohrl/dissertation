\chapter[Revisão teórica]{Revisão teórica} \label{cap:cap1}
Colocar texto aqui 

% 2a seção do capítulo 1
\section{Sistemas Multi-robos} \label{sec:sec1_2}
Colocar texto aqui

% 1a sub-seção da 2a seção do capítulo 1
\subsection{Taxonomias} \label{sub:sub1_2_1}
Colocar texto aqui

% 3a seção do capítulo 1
\section{Alocação de Tarefas} \label{sec:sec1_3}
Colocar texto aqui

% 4a seção do capítulo 1
\section{Recursos} \label{sec:sec1_4}

Colocar texto aqui

\section{Sistema Multi-Agente}

\subsection{Agentes}

%According to \cite{ref:russell1995aima}:

an \textbf{agent} is anything that can be viewed as \textbf{perceiving} its environment through \textbf{sensors} and \textbf{acting} upon that environment through \textbf{effectors}.

%Talking about \textbf{rational agent}:

the \textbf{performance measure} determines how successful an agent is. The complete perceptual history is called \textbf{percept sequence}.

So, it is desired to measure its performance over the long run.
a rational agent is not omniscient. 

Saying that, we cannot blame an agent for failing to take into account something it could not perceive, or for failing to take an action that it is incapable of taking.

In other words, what is rational at any given time depends on:
\begin{itemize}
    \item The performance measure that defines degree of success;
    \item Everything that the agent has perceived so far, that is, the percept sequence;
    \item What the agent knowsabout the environment;
    \item and, finally, the actions that the agent can perform.
\end{itemize}

\cite{ref:russell1995aima} defines an \textbf{ideal rational agent} as: \textit{For each possible percept sequence, an ideal rational agent should do whatever action is expected to maximize its performance measure, an the basis of the evidence provided by the percept sequence and whatever built-in knowledge the agent has}.

\textbf{ideal mapping}: Specifying which action an agent ought to take in response to any given percept sequence provides a design for an ideal agent.

Talking about autonomy: If the agent's actions are based completely on built-in knownledge, such that it need pay no attention to its percepts, then we say that tthe agent lacks \textbf{autonomy}.

The job of AI is to design the \textbf{agent program}: a function that implements the agent mapping from percepts to actions. We assume this program will run on sort of computing device: the \textbf{architecture}.

There exists fours types of agent program:
\begin{itemize}
    \item \textbf{Simple reflex agents}:
    \item \textbf{Agents that keep track of the world}:
    \item \textbf{Goal-based agents}:
    \item \textbf{Utility-based agents}:
\end{itemize}

This paper deals with utility-based agents!!!

To sum up, ...


\subsection{Objetos}

\subsection{Ambiente}

\section{Sistema Multi-Robô}

\section{Alocação de Tarefas Multi-Robô}

\section{Arquiteturas de Alocação de Tarefas Multi-Robô}

\subsection{Arquiteturas baseadas em Mercado}

\begin{itemize}
    \item \textbf{Murdoch}:
    \item \textbf{M+}:
\end{itemize}

\subsection{Arquiteturas baseadas em Comportamento}

\begin{itemize}
    \item \textbf{Alliance}:
    
\end{itemize}


\textbf{Resource-constrained project scheduling problem}
The RCPSP problem is a generalization of the production-specific Job-Shop, Flow-Shop and Open-Shop scheduling problems. Given

    a set of q resources with given capacities,
    a set of q resources with given capacities,
    a network of precedence constraints between the activities, and
    for each activity and each resource the amount of the resource required by the activity over its execution,

the goal of the RCPSP problem is to find a schedule meeting all the constraints whose makespan (i.e., the time at which all activities are finished) is minimal.


\subsection{Comparing DAIs, MASs, and MRSs}

Distributed Artificial Intelligence (DAI) has existed as a subfield of AI for less than two decades. DAI is concerned with systems that consist of multiple independent entities that interact in a domain. Traditionally, DAI has been divided into two sub-disciplines: Distributed Problem Solving (DPS) focuses on the information management aspects of systems with several components working together towards a common goal; Multiagent Systems (MAS) deals with behavior management in collections of several independent entities, or agents. This survey of MAS is intended to serve as an introduction to the field and as an organizational framework. A series of general multiagent scenarios are presented. For each scenario, the issues that arise are described along with a sampling of the techniques that exist to deal with them. The presented techniques are not exhaustive, but they highlight how multiagent systems can be and have been used to build complex systems. When options exist, the techniques presented are biased towards machine learning approaches. Additional opportunities for applying machine learning to MAS are highlighted and robotic soccer is presented as an appropriate test bed for MAS. This survey does not focus exclusively on robotic systems. However, we believe that much of the prior research in non-robotic MAS is relevant to robotic MAS, and we explicitly discuss several robotic MAS, including all of those presented in this issue \cite{ref:stone2000multiagent}.